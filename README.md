# ğŸ“Œ Pipeline de Recrutamento Otimizado

Bem-vindo ao repositÃ³rio do **Pipeline de Recrutamento Otimizado**, uma soluÃ§Ã£o robusta e modular para automatizaÃ§Ã£o de processos de recrutamento e seleÃ§Ã£o, integrando dados de vagas e candidatos com anÃ¡lises avanÃ§adas e aprendizado de mÃ¡quina.

## ğŸ“ Sobre o Projeto

Este projeto visa otimizar o processo de **ranqueamento e anÃ¡lise** de candidatos baseado em sua compatibilidade com vagas, a partir de dados estruturados e tÃ©cnicas de aprendizado de mÃ¡quina. 

Principais funcionalidades:
- **AutomaÃ§Ã£o** de coleta, limpeza e prÃ©-processamento de dados.
- **Engenharia de Features** para avaliaÃ§Ã£o detalhada dos candidatos em relaÃ§Ã£o Ã s vagas.
- **Modelagem Preditiva** utilizando **LightGBM** para propor rankings confiÃ¡veis.
- **Painel Interativo** com filtros avanÃ§ados permitindo a anÃ¡lise dinÃ¢mica dos resultados.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```plaintext
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ applicants_raw.json
â”‚   â”‚   â”œâ”€â”€ prospects_raw.json
â”‚   â”‚   â””â”€â”€ vagas_raw.json
â”‚   â”œâ”€â”€ candidatos.csv
â”‚   â””â”€â”€ vagas.csv
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ artefatos_features.joblib
â”‚   â”œâ”€â”€ colunas_training.joblib
â”‚   â”œâ”€â”€ exemplo_tn_streamlit.csv
â”‚   â”œâ”€â”€ exemplo_tp_streamlit.csv
â”‚   â””â”€â”€ modelo_recrutamento_rf.joblib
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ modelo_recrutamento_rf.py      # CÃ³digo de prÃ©-processamento.
â”‚
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o principal (este arquivo).
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto.

```

## ğŸ”§ Tecnologias Utilizadas
- **Linguagem:** Python `>=3.8`
- **Bibliotecas Essenciais:**
  - **ManipulaÃ§Ã£o de Dados:** `pandas`, `numpy`
  - **Aprendizado de MÃ¡quina:** `lightgbm`, `scikit-learn`
  - **Deploy Interativo:** `streamlit`
  - **SerializaÃ§Ã£o e PersistÃªncia:** `joblib`

---

## ğŸš€ Como Executar

1. Certifique-se de ter o **Python 3.8+** instalado.
2. Clone este repositÃ³rio em sua mÃ¡quina local:
   ```bash
   git clone https://github.com/Kbetti/datathon_decision.git
   cd datathon_decision

## ğŸ› ï¸ Pipeline Detalhado


### Etapas do Pipeline
1. **ExtraÃ§Ã£o e PrÃ©-processamento**
   
Entrada:
Arquivos JSON contendo os dados brutos das vagas (vagas.json) e dos candidatos (candidatos.json).


AÃ§Ãµes Realizadas:

PadronizaÃ§Ã£o de colunas, como:
nivel_academico
nivel_profissional
pcd (Pessoa com DeficiÃªncia)
Tratamento de duplicatas e valores ausentes nos dados.
Uso de expressÃµes regulares para consolidar competÃªncias tÃ©cnicas nas colunas _skills.

2. **Engenharia de Features**

   
CriaÃ§Ã£o de Atributos:

Compatibilidade LinguÃ­stica: Avalia se o candidato atende os requisitos de idiomas (e.g. inglÃªs e espanhol) exigidos pela vaga.

Skills Match: Calcula o nÃºmero total de _skills compatÃ­veis entre o candidato e a vaga.

AnÃ¡lise de Gaps: Identifica as skills exigidas pela vaga que o candidato nÃ£o possui.


3. **Modelagem**

   
Modelo Utilizado:

LightGBM, escolhido por sua performance e eficiÃªncia em conjuntos de dados relativamente grandes.

ConfiguraÃ§Ãµes do Modelo:

Principais hiperparÃ¢metros:
n_estimators=200
learning_rate=0.05
max_depth=7
Balanceamento das classes-alvo para lidar com desbalanceamento nos dados.
PersistÃªncia de Artefatos:

Modelo treinado, colunas-chave e artefatos de engenharia de features sÃ£o salvos usando o Joblib.

4. **SaÃ­da**
O navegador serÃ¡ aberto automaticamente com o painel interativo, onde vocÃª poderÃ¡ explorar:
Dados processados.
Detalhes das melhores prediÃ§Ãµes e insights gerados.

## ğŸ“Œ Desenvolvimento Futuro

ImplementaÃ§Ã£o de novos indicadores de compatibilidade.

IntegraÃ§Ã£o de funcionalidades hÃ­bridas no modelo.

